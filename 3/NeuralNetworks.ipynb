{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this exercise we will train some neural network using Pytorch.\\nInstallation instructions: https://pytorch.org/get-started/locally/\\n\\nI recommend to run this exercise in colab using GPU or in kaggle notebooks.\\nYou should find something like: Runtime -> Change runtime type -> T4 GPU to access GPU there.\\nEverything thing you need is preinstalled there.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this exercise we will train some neural network using Pytorch.\n",
    "Installation instructions: https://pytorch.org/get-started/locally/\n",
    "\n",
    "I recommend to run this exercise in colab using GPU or in kaggle notebooks.\n",
    "You should find something like: Runtime -> Change runtime type -> T4 GPU to access GPU there.\n",
    "Everything thing you need is preinstalled there.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because outside world is ugly (in console 'export OMP_NUM_THREADS=1')\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch is library for dealing with neural networks (and automatic gradients)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Torchvision is helper library for pytorch to deal with computer vision\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usamec/anaconda3/envs/magic_train/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prepare dataset, whole lecture will be done over MNIST dataset\"\"\"\n",
    "batch_size_train = 256\n",
    "batch_size_test = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256]) tensor([0, 3, 9, 0, 5, 3, 7, 1, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "# What is in train?\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape, y[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f022ed046a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X: 256 images, 1 channel (black/white), 28x28 image\n",
    "# We will flatten each image into one vector for now\n",
    "# Y: One number (category of image)\n",
    "# Images looks like this:\n",
    "\n",
    "plt.imshow(x[0,0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', torch.Size([10, 784])), ('bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear model (multiclass logistic regression)\n",
    "# This just computes scores for each class\n",
    "# This layer has parameters W, b and does (input.matmul(W.T) + b)\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "[(name, p.shape) for name, p in model_linear.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4424, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute loss for one batch of images\n",
    "output = model_linear(x.flatten(1))\n",
    "log_probs = F.log_softmax(output, dim=-1)    # log_softmax(.) = log(softmax(.))\n",
    "loss = F.nll_loss(log_probs, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4424, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch has many loss functions, which look similar but take different things,\n",
    "# so take care\n",
    "# Here cross entropy(output, y) is same as nll_loss(log_softmax(output), y)\n",
    "loss2 = F.cross_entropy(output, y)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0137,  0.0137,  0.0137,  ...,  0.0137,  0.0137,  0.0137],\n",
       "        [ 0.0080,  0.0080,  0.0080,  ...,  0.0080,  0.0080,  0.0080],\n",
       "        [ 0.0164,  0.0164,  0.0164,  ...,  0.0164,  0.0164,  0.0164],\n",
       "        ...,\n",
       "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
       "        [ 0.0049,  0.0049,  0.0049,  ...,  0.0049,  0.0049,  0.0049],\n",
       "        [-0.0107, -0.0107, -0.0107,  ..., -0.0107, -0.0107, -0.0107]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to train model, we need to get gradients\n",
    "# This is easy, gradient will magically appear\n",
    "loss.backward()\n",
    "model_linear.weight.grad\n",
    "\n",
    "# If you really want to do things by hand\n",
    "# model_linear.weight.data = model_linear.weight.data - 0.01 * model_linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0274,  0.0274,  0.0274,  ...,  0.0274,  0.0274,  0.0274],\n",
       "        [ 0.0160,  0.0160,  0.0160,  ...,  0.0160,  0.0160,  0.0160],\n",
       "        [ 0.0329,  0.0329,  0.0329,  ...,  0.0329,  0.0329,  0.0329],\n",
       "        ...,\n",
       "        [ 0.0034,  0.0034,  0.0034,  ...,  0.0034,  0.0034,  0.0034],\n",
       "        [ 0.0098,  0.0098,  0.0098,  ...,  0.0098,  0.0098,  0.0098],\n",
       "        [-0.0215, -0.0215, -0.0215,  ..., -0.0215, -0.0215, -0.0215]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we calculate gradient second time, it will accumulate\n",
    "output = model_linear(x.flatten(1))\n",
    "log_probs = F.log_softmax(output, dim=-1)    # log_softmax(.) = log(softmax(.))\n",
    "loss = F.nll_loss(log_probs, y)\n",
    "loss.backward()\n",
    "model_linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 2.00052149207034\n",
      "epoch 1 training loss 1.2760408939199244\n",
      "epoch 2 training loss 1.191791332148491\n",
      "epoch 3 training loss 1.1462283043151207\n",
      "epoch 4 training loss 1.0351847174319815\n"
     ]
    }
   ],
   "source": [
    "# Lets optimize, this is typical pytorch training loop you will see a lot with some modifications\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "optimizer = torch.optim.SGD(model_linear.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    for x, y in train_loader:\n",
    "        # Here we calculate output from the model, note that we flatten the input (converts 256,1,28,28 to 256,784) \n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        # Here we calculate loss\n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        # Here we calculate gradients, first we need to zero previous ones\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        # And here we update the weights\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "    print(\"epoch\", epoch, \"training loss\", total_loss / total_loss_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 1.951 training accuracy 0.834 testing accuracy 0.880\n",
      "epoch 1 training loss 1.338 training accuracy 0.871 testing accuracy 0.859\n",
      "epoch 2 training loss 1.168 training accuracy 0.878 testing accuracy 0.871\n",
      "epoch 3 training loss 1.191 training accuracy 0.878 testing accuracy 0.882\n",
      "epoch 4 training loss 1.085 training accuracy 0.880 testing accuracy 0.874\n",
      "epoch 5 training loss 1.052 training accuracy 0.885 testing accuracy 0.819\n",
      "epoch 6 training loss 1.052 training accuracy 0.884 testing accuracy 0.892\n",
      "epoch 7 training loss 1.063 training accuracy 0.885 testing accuracy 0.887\n",
      "epoch 8 training loss 1.039 training accuracy 0.885 testing accuracy 0.865\n",
      "epoch 9 training loss 1.050 training accuracy 0.885 testing accuracy 0.907\n"
     ]
    }
   ],
   "source": [
    "# Optimize and compute training accuracy and test accuracy\n",
    "\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "optimizer = torch.optim.SGD(model_linear.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        # This calulcates accuracy\n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0388,  0.1307, -0.2220,  0.0209, -0.0893, -0.2690, -0.1389, -0.2647,\n",
       "         -0.0757, -0.2917],\n",
       "        [-0.2254,  0.0284,  0.1106, -0.3431, -0.1479, -0.2410,  0.1822,  0.0154,\n",
       "          0.2372,  0.0017],\n",
       "        [ 0.3014, -0.1125,  0.1806,  0.1344,  0.2504,  0.1933, -0.0045, -0.2011,\n",
       "          0.3596,  0.0291],\n",
       "        [-0.1752,  0.2518, -0.3156, -0.1780, -0.0343, -0.1783,  0.0321, -0.2541,\n",
       "          0.3890, -0.7036],\n",
       "        [-0.0637, -0.1810, -0.1249, -0.2442, -0.4494, -0.2623, -0.2865, -0.2943,\n",
       "          0.2449, -0.6921],\n",
       "        [-0.3282, -0.2350, -0.4335,  0.0862, -0.0895, -0.3210,  0.6854, -0.2567,\n",
       "         -0.2212, -0.3431],\n",
       "        [-0.3149, -0.0967, -0.1309, -0.1375, -0.4409,  0.0913,  0.1726, -0.0405,\n",
       "          0.7088, -0.4498],\n",
       "        [-0.1807,  0.1501,  0.0303,  0.1532,  0.1420, -0.3575,  0.1475,  0.1872,\n",
       "          0.3412, -0.1423],\n",
       "        [-0.4604, -0.3253,  0.1288, -0.2578,  0.2968, -0.1051,  0.0454, -0.0824,\n",
       "         -0.0895, -0.1224],\n",
       "        [-0.1738, -0.0353,  0.1627, -0.0975, -0.0876,  0.1573,  0.2922, -0.0027,\n",
       "          0.7506, -0.3607]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how you define a simple neural network in Pytorch\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "model(torch.randn((10,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 1.794 training accuracy 0.457 testing accuracy 0.406\n",
      "epoch 1 training loss 1.351 training accuracy 0.503 testing accuracy 0.566\n",
      "epoch 2 training loss 1.137 training accuracy 0.627 testing accuracy 0.634\n",
      "epoch 3 training loss 1.106 training accuracy 0.600 testing accuracy 0.654\n",
      "epoch 4 training loss 1.098 training accuracy 0.590 testing accuracy 0.585\n",
      "epoch 5 training loss 1.077 training accuracy 0.601 testing accuracy 0.710\n",
      "epoch 6 training loss 0.785 training accuracy 0.730 testing accuracy 0.723\n",
      "epoch 7 training loss 0.603 training accuracy 0.810 testing accuracy 0.807\n",
      "epoch 8 training loss 0.433 training accuracy 0.881 testing accuracy 0.894\n",
      "epoch 9 training loss 0.368 training accuracy 0.906 testing accuracy 0.898\n"
     ]
    }
   ],
   "source": [
    "# Let's train neural network, we only change model and maybe learning rate\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1, momentum=0.0)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = model(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        output = model(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# How to run on cuda (this optional, if you have GPU access, e.g. in colab or kaggle notebooks)\\n# No need to run this cell\\n\\nmodel = nn.Sequential(\\n    nn.Linear(28*28, 256),\\n    nn.ReLU(),\\n    nn.Linear(256, 10)\\n)\\n# Move model to GPU. Instead of x.cuda() you can also use x.to(device) where device is \"cpu\" or \"cuda\" so your code\\n# is nicely parametrized.\\n\\nmodel.cuda()\\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)\\n\\nfor epoch in range(10):\\n    total_loss = 0\\n    total_loss_cc = 0\\n    total_good = 0\\n    total_samples = 0\\n    \\n    for x, y in train_loader:\\n        # Move input and labels to GPU\\n        output = model(x.cuda().flatten(1))\\n        y = y.cuda()\\n        log_probs = F.log_softmax(output, dim=-1)\\n        \\n        prediction = log_probs.argmax(dim=-1)\\n        total_good += (prediction == y).sum().item()\\n        total_samples += y.shape[0]\\n        \\n        batch_loss = F.nll_loss(log_probs, y)\\n        optimizer.zero_grad()\\n        batch_loss.backward()\\n        optimizer.step()\\n        total_loss += batch_loss.item()\\n        total_loss_cc += 1\\n        \\n    total_good_test = 0\\n    total_samples_test = 0\\n    for x, y in test_loader:\\n        # Move input and labels to GPU\\n        y = y.cuda()\\n        output = model(x.cuda().flatten(1))\\n        log_probs = F.log_softmax(output, dim=-1)\\n        \\n        prediction = log_probs.argmax(dim=-1)\\n        total_good_test += (prediction == y).sum().item()\\n        total_samples_test += y.shape[0]\\n        \\n    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \\n          \"training accuracy %.3f\" % (total_good / total_samples), \\n          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))\\n          \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# How to run on cuda (this optional, if you have GPU access, e.g. in colab or kaggle notebooks)\n",
    "# No need to run this cell\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "# Move model to GPU. Instead of x.cuda() you can also use x.to(device) where device is \"cpu\" or \"cuda\" so your code\n",
    "# is nicely parametrized.\n",
    "\n",
    "model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        # Move input and labels to GPU\n",
    "        output = model(x.cuda().flatten(1))\n",
    "        y = y.cuda()\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        # Move input and labels to GPU\n",
    "        y = y.cuda()\n",
    "        output = model(x.cuda().flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))\n",
    "          \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTask 1.\\nIn example above figure out best settings for learning rate a momentum in the optimizer.\\nKeep the number of epochs to 10. Also keep the learning constant during training.\\nSumarize your findings in some chart or table.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 1.\n",
    "In example above figure out best settings for learning rate a momentum in the optimizer.\n",
    "Keep the number of epochs to 10. Also keep the learning constant during training.\n",
    "Sumarize your findings in some chart or table.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTask 2.\\nHere is network with 2 hidden layers (each additional hidden layer we add nn.Linear(256,256) and nn.ReLU())\\n\\nmodel = nn.Sequential(\\n    nn.Linear(28*28, 256),\\n    nn.ReLU(),\\n    nn.Linear(256, 256),\\n    nn.ReLU(),\\n    nn.Linear(256, 256),\\n    nn.ReLU(),\\n    nn.Linear(256, 10)\\n)\\n\\nHow does adding more hidden layers influence final accuracy (try 3-6 hidden layers).\\nAlways figure out the best optimizer settings. Again run for 10 epochs.\\nAgain produce some chart or table (maybe with accuracy changes over time).\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 2.\n",
    "Here is network with 2 hidden layers (each additional hidden layer we add nn.Linear(256,256) and nn.ReLU())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "How does adding more hidden layers influence final accuracy (try 3-6 hidden layers).\n",
    "Always figure out the best optimizer settings. Again run for 10 epochs.\n",
    "Again produce some chart or table (maybe with accuracy changes over time).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere is an example of a simple convolutional network. They are really good on images.\\nE.g. ResNet is a very strong baseline for any image task https://pytorch.org/vision/main/models/resnet.html\\nOr convnext: https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/convnext.py\\n\\nmodel = nn.Sequential(\\n    nn.Conv2d(1, 16, 5, padding=2, stride=2),  # Here we get 14x14 image with 16 channels\\n    nn.ReLU(),\\n    nn.Conv2d(16, 16, 3, padding='same'),\\n    nn.ReLU(),\\n    nn.Conv2d(16, 32, 3, padding=1, stride=2),  # Here we get 7x7 image with 32 channels\\n    nn.ReLU(),\\n    nn.Conv2d(32, 32, 3, padding='same'),\\n    nn.ReLU(),\\n    nn.Flatten(),\\n    nn.Linear(7*7*32, 10)\\n)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here is an example of a simple convolutional network. They are really good on images.\n",
    "E.g. ResNet is a very strong baseline for any image task https://pytorch.org/vision/main/models/resnet.html\n",
    "Or convnext: https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/convnext.py\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, 5, padding=2, stride=2),  # Here we get 14x14 image with 16 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, padding=1, stride=2),  # Here we get 7x7 image with 32 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7*7*32, 10)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also define neural networks as modules.\n",
    "# This is same model as \n",
    "# model = nn.Sequential(\n",
    "#    nn.Linear(28*28, 256),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(256, 10)\n",
    "#)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(28*28, 256)\n",
    "        self.b = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.b(x)\n",
    "        return x\n",
    "    \n",
    "#model = MyModel()\n",
    "#model(torch.rand(50, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 4:\n",
    "\n",
    "Usually layers in neural networks need to be initialized with some random values (pytorch handles this for you).\n",
    "If you initialize all layers to zeroes, network will not train.\n",
    "But if you initialize only some of them to zeroes, network will train and all layers will get updated at some points of the training.\n",
    "Your task is to figure out which layers you can initialize with zeroes.\n",
    "\n",
    "\n",
    "Consider following two models (ModelA and ModelB).\n",
    "Which layers in those models can be initialized to zeroes and model will still train\n",
    "(that means: all layers will be updated at some point of the training)? \n",
    "Ideal answer should contain: theoretical justification and also experimental result (successful training)\n",
    "\"\"\"\n",
    "\n",
    "class ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(28*28, 256, bias=False) # bias=False means, that transformation is xW instead of xW + b\n",
    "        self.a.weight.data *= 0  # This sets weights of a to zero\n",
    "        self.b = nn.Linear(256, 256, bias=False)\n",
    "        self.b.weight.data *= 0  # This sets weights of b to zero\n",
    "        self.c = nn.Linear(256, 10, bias=False)\n",
    "        self.c.weight.data *= 0  # This sets weights of c to zero\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.a(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.b(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.c(x)\n",
    "        return x\n",
    "    \n",
    "class ModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(28*28, 256, bias=False)\n",
    "        self.a.weight.data *= 0  \n",
    "        self.b1 = nn.Linear(256, 256, bias=False)\n",
    "        self.b1.weight.data *= 0 \n",
    "        self.b2 = nn.Linear(256, 256, bias=False)\n",
    "        self.b2.weight.data *= 0 \n",
    "        self.c1 = nn.Linear(256, 256, bias=False)\n",
    "        self.c1.weight.data *= 0 \n",
    "        self.c2 = nn.Linear(256, 256, bias=False)\n",
    "        self.c2.weight.data *= 0 \n",
    "        self.o = nn.Linear(256, 10, bias=False)\n",
    "        self.o.weight.data *= 0  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.a(x)\n",
    "        z = torch.relu(x)\n",
    "        z = self.b1(z)\n",
    "        z = torch.relu(x)\n",
    "        z = self.b2(z)\n",
    "        x = x + z\n",
    "        z = torch.relu(x)\n",
    "        z = self.c1(z)\n",
    "        z = torch.relu(x)\n",
    "        z = self.c2(z)\n",
    "        x = x + z\n",
    "        x = self.o(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
