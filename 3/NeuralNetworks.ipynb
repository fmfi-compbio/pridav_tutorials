{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this exercise we will train some neural network using Pytorch.\\nInstallation instructions: https://pytorch.org/get-started/locally/\\n\\nI recommend to run this exercise in colab using GPU or in kaggle notebooks.\\nYou should find something like: Runtime -> Change runtime type -> T4 GPU to access GPU there.\\nEverything thing you need is preinstalled there.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this exercise we will train some neural network using Pytorch.\n",
    "Installation instructions: https://pytorch.org/get-started/locally/\n",
    "\n",
    "I recommend to run this exercise in colab using GPU or in kaggle notebooks.\n",
    "You should find something like: Runtime -> Change runtime type -> T4 GPU to access GPU there.\n",
    "Everything thing you need is preinstalled there.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because outside world is ugly (in console 'export OMP_NUM_THREADS=1')\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch is library for dealing with neural networks (and automatic gradients)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Torchvision is helper library for pytorch to deal with computer vision\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usamec/anaconda3/envs/magic_train/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prepare dataset, whole lecture will be done over MNIST dataset\"\"\"\n",
    "batch_size_train = 256\n",
    "batch_size_test = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256]) tensor([9, 5, 6, 8, 5, 1, 2, 2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# What is in train?\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape, y[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda4a412b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X: 256 images, 1 channel (black/white), 28x28 image\n",
    "# We will flatten each image into one vector for now\n",
    "# Y: One number (category of image)\n",
    "# Images looks like this:\n",
    "\n",
    "plt.imshow(x[0,0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', torch.Size([10, 784])), ('bias', torch.Size([10]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear model from last lecture\n",
    "# This just computes scores for each class\n",
    "# This layer has parameters W, b and does (input.matmul(W.T) + b)\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "[(name, p.shape) for name, p in model_linear.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5075, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute loss for one batch of images\n",
    "output = model_linear(x.flatten(1))\n",
    "log_probs = F.log_softmax(output, dim=-1)    # log_softmax(.) = log(softmax(.))\n",
    "loss = F.nll_loss(log_probs, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5075, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch has many loss functions, which look similar but take different things,\n",
    "# so take care\n",
    "# Here cross entropy(output, y) is same as nll_loss(log_softmax(output), y)\n",
    "loss2 = F.cross_entropy(output, y)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0329, -0.0329, -0.0329,  ..., -0.0329, -0.0329, -0.0329],\n",
       "        [ 0.0016,  0.0016,  0.0016,  ...,  0.0016,  0.0016,  0.0016],\n",
       "        [ 0.0044,  0.0044,  0.0044,  ...,  0.0044,  0.0044,  0.0044],\n",
       "        ...,\n",
       "        [ 0.0147,  0.0147,  0.0147,  ...,  0.0147,  0.0147,  0.0147],\n",
       "        [ 0.0062,  0.0062,  0.0062,  ...,  0.0062,  0.0062,  0.0062],\n",
       "        [ 0.0087,  0.0087,  0.0087,  ...,  0.0087,  0.0087,  0.0087]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to train model, we need to get gradients\n",
    "# This is easy, gradient will magically appear\n",
    "loss.backward()\n",
    "model_linear.weight.grad\n",
    "\n",
    "# If you really want to do things by hand\n",
    "# model_linear.weight.data = model_linear.weight.data - 0.01 * model_linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0658, -0.0658, -0.0658,  ..., -0.0658, -0.0658, -0.0658],\n",
       "        [ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033],\n",
       "        [ 0.0088,  0.0088,  0.0088,  ...,  0.0088,  0.0088,  0.0088],\n",
       "        ...,\n",
       "        [ 0.0294,  0.0294,  0.0294,  ...,  0.0294,  0.0294,  0.0294],\n",
       "        [ 0.0124,  0.0124,  0.0124,  ...,  0.0124,  0.0124,  0.0124],\n",
       "        [ 0.0173,  0.0173,  0.0173,  ...,  0.0173,  0.0173,  0.0173]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we calculate gradient second time, it will accumulate\n",
    "output = model_linear(x.flatten(1))\n",
    "log_probs = F.log_softmax(output, dim=-1)    # log_softmax(.) = log(softmax(.))\n",
    "loss = F.nll_loss(log_probs, y)\n",
    "loss.backward()\n",
    "model_linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 2.274541570531561\n",
      "epoch 1 training loss 1.2374114778447658\n",
      "epoch 2 training loss 1.1863635533667625\n",
      "epoch 3 training loss 1.1060615998633365\n",
      "epoch 4 training loss 1.1890613818422278\n"
     ]
    }
   ],
   "source": [
    "# Lets optimize, this is typical pytorch training loop you will see a lot with some modifications\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "optimizer = torch.optim.SGD(model_linear.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    for x, y in train_loader:\n",
    "        # Here we calculate output from the model, note that we flatten the input (converts 256,1,28,28 to 256,784) \n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        # Here we calculate loss\n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        # Here we calculate gradients, first we need to zero previous ones\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        # And here we update the weights\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "    print(\"epoch\", epoch, \"training loss\", total_loss / total_loss_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 2.009 training accuracy 0.832 testing accuracy 0.696\n",
      "epoch 1 training loss 1.309 training accuracy 0.868 testing accuracy 0.856\n",
      "epoch 2 training loss 1.185 training accuracy 0.878 testing accuracy 0.824\n",
      "epoch 3 training loss 1.065 training accuracy 0.881 testing accuracy 0.898\n",
      "epoch 4 training loss 1.154 training accuracy 0.878 testing accuracy 0.896\n",
      "epoch 5 training loss 1.096 training accuracy 0.884 testing accuracy 0.877\n",
      "epoch 6 training loss 1.100 training accuracy 0.885 testing accuracy 0.886\n",
      "epoch 7 training loss 1.061 training accuracy 0.885 testing accuracy 0.908\n",
      "epoch 8 training loss 1.115 training accuracy 0.884 testing accuracy 0.907\n",
      "epoch 9 training loss 1.120 training accuracy 0.887 testing accuracy 0.890\n"
     ]
    }
   ],
   "source": [
    "# Optimize and compute training accuracy and test accuracy\n",
    "\n",
    "model_linear = nn.Linear(28*28, 10)\n",
    "optimizer = torch.optim.SGD(model_linear.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        # This calulcates accuracy\n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        output = model_linear(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1063, -0.0495, -0.2421, -0.1830, -0.3833, -0.0672, -0.1323, -0.3067,\n",
       "         -0.0515,  0.0095],\n",
       "        [ 0.1249, -0.1272, -0.1323, -0.0771, -0.5209,  0.2859, -0.0053,  0.0159,\n",
       "          0.1288, -0.0543],\n",
       "        [ 0.0879,  0.1431,  0.2058,  0.0300,  0.0035, -0.4652,  0.3180, -0.0816,\n",
       "          0.3194, -0.0390],\n",
       "        [-0.1388, -0.0740, -0.3046,  0.2811, -0.2061,  0.4380,  0.1307,  0.0327,\n",
       "         -0.0011, -0.4125],\n",
       "        [ 0.1923, -0.0686, -0.1078, -0.1517, -0.0753, -0.0714,  0.2345, -0.2096,\n",
       "         -0.2972, -0.2264],\n",
       "        [-0.0712,  0.3517,  0.0309, -0.2169, -0.4148,  0.0008,  0.2375, -0.0196,\n",
       "         -0.2262, -0.2258],\n",
       "        [ 0.3602, -0.2279,  0.1028, -0.0144,  0.1959, -0.2619,  0.1685, -0.0426,\n",
       "         -0.0902,  0.1854],\n",
       "        [ 0.1064, -0.0445, -0.2153, -0.0236, -0.4611,  0.1382,  0.0954, -0.4292,\n",
       "          0.2608,  0.0428],\n",
       "        [ 0.0572, -0.0269, -0.1442,  0.3465,  0.0454, -0.0184,  0.2459, -0.0549,\n",
       "         -0.0249, -0.2102],\n",
       "        [ 0.0555,  0.3516, -0.0753, -0.2231,  0.1757, -0.4235,  0.1638, -0.2294,\n",
       "         -0.1050, -0.2490]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "model(torch.randn((10,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training loss 1.861 training accuracy 0.406 testing accuracy 0.465\n",
      "epoch 1 training loss 1.403 training accuracy 0.500 testing accuracy 0.403\n",
      "epoch 2 training loss 0.983 training accuracy 0.651 testing accuracy 0.776\n",
      "epoch 3 training loss 0.513 training accuracy 0.843 testing accuracy 0.901\n",
      "epoch 4 training loss 0.719 training accuracy 0.756 testing accuracy 0.707\n",
      "epoch 5 training loss 0.625 training accuracy 0.793 testing accuracy 0.662\n",
      "epoch 6 training loss 0.931 training accuracy 0.688 testing accuracy 0.890\n",
      "epoch 7 training loss 0.563 training accuracy 0.831 testing accuracy 0.875\n",
      "epoch 8 training loss 0.491 training accuracy 0.853 testing accuracy 0.829\n",
      "epoch 9 training loss 0.391 training accuracy 0.900 testing accuracy 0.893\n"
     ]
    }
   ],
   "source": [
    "# Let's train neural network, we only change model and maybe learning rate\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1, momentum=0.0)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = model(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        output = model(x.flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# How to run on cuda (this optional, if you have GPU access, vyuka does not have one, colab does)\n",
    "# No need to run this cell\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "# Move model to GPU. Instead of x.cuda() you can also use x.to(device) where device is \"cpu\" or \"cuda\" so your code\n",
    "# is nicely parametrized.\n",
    "\n",
    "model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_loss_cc = 0\n",
    "    total_good = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        # Move input and labels to GPU\n",
    "        output = model(x.cuda().flatten(1))\n",
    "        y = y.cuda()\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good += (prediction == y).sum().item()\n",
    "        total_samples += y.shape[0]\n",
    "        \n",
    "        batch_loss = F.nll_loss(log_probs, y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "        total_loss_cc += 1\n",
    "        \n",
    "    total_good_test = 0\n",
    "    total_samples_test = 0\n",
    "    for x, y in test_loader:\n",
    "        # Move input and labels to GPU\n",
    "        y = y.cuda()\n",
    "        output = model(x.cuda().flatten(1))\n",
    "        log_probs = F.log_softmax(output, dim=-1)\n",
    "        \n",
    "        prediction = log_probs.argmax(dim=-1)\n",
    "        total_good_test += (prediction == y).sum().item()\n",
    "        total_samples_test += y.shape[0]\n",
    "        \n",
    "    print(\"epoch\", epoch, \"training loss %.3f\" % (total_loss / total_loss_cc), \n",
    "          \"training accuracy %.3f\" % (total_good / total_samples), \n",
    "          \"testing accuracy %.3f\" % (total_good_test / total_samples_test))\n",
    "          \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1.\n",
    "In example above figure out best settings for learning rate a momentum in the optimizer.\n",
    "Keep the number of epochs to 10. Also keep the learning constant during training.\n",
    "Sumarize your findings in some chart or table.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 2.\n",
    "Here is network with 2 hidden layers (each additional hidden layer we add nn.Linear(256,256) and nn.ReLU())\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "How does adding more hidden layers influence final accuracy (try 3-6 hidden layers).\n",
    "Always figure out the best optimizer settings. Again run for 10 epochs.\n",
    "Again produce some chart or table (maybe with accuracy changes over time).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 3.\n",
    "Here is an example of convolutional network. Do not change it for this task.\n",
    "Only figure out best settings for the optimizer. Also run for only 10 epochs.\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, 5, padding=2, stride=2),  # Here we get 14x14 image with 16 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, padding=1, stride=2),  # Here we get 7x7 image with 32 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7*7*32, 10)\n",
    ")\n",
    "\n",
    "Run training of convolutional network and report the results and compare with best results from above.\n",
    "Also, there is no need to flatten the input now. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, 5, padding=1, stride=2),  # Here we get 14x14 image with 16 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, padding=1, stride=2),  # Here we get 7x7 image with 32 channels\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3, padding='same'),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7*7*32, 10)\n",
    ")\n",
    "model(torch.randn(10,1,28,28)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 4 bonus:\n",
    "Change neural architecture like you want and achive best accuracy in 10 epochs.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
